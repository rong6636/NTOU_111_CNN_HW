{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c23055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "class Gopro_Loader(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 讀取所有影像的檔名\n",
    "        self.imgs = glob.glob(os.path.join(data_path, 'blur/*.png'))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 讀取影像\n",
    "        img_path = self.imgs[idx]\n",
    "        label_path = img_path.replace(\"blur\", \"sharp\")\n",
    "        \n",
    "        # 讀取標籤\n",
    "        img = Image.open(img_path)\n",
    "        label = Image.open(label_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            label = self.transform(label)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "558f9969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class double_convolution(nn.Module):\n",
    "    #(convolution => [BN] => ReLU) * 2\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(double_convolution,self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "\n",
    "class Down(nn.Module):\n",
    "    #Downscaling with maxpool then double conv\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Down,self).__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            double_convolution(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    #Upscaling then double conv\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Up, self).__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        self.conv = double_convolution(in_channels, out_channels)\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "    def forward(self, x, x1):\n",
    "        x = self.up(x)\n",
    "        x1 = F.interpolate(x1, size=(x.size()[2], x.size()[3]))\n",
    "\n",
    "        x = torch.cat([x1, x], dim=1)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e06d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.conv_block = double_convolution(3, 64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024)\n",
    "        self.up1 = Up(1024, 512)\n",
    "        self.up2 = Up(512, 256)\n",
    "        self.up3 = Up(256, 128)\n",
    "        self.up4 = Up(128, 64)\n",
    "        self.out = nn.Conv2d(64, 3, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         print(\"x shape:\", x.shape)\n",
    "        \n",
    "        x1 = self.conv_block(x)\n",
    "#         print(\"x1 shape:\", x1.shape)\n",
    "        x2 = self.down1(x1)\n",
    "#         print(\"x2 shape:\", x2.shape)\n",
    "        x3 = self.down2(x2)\n",
    "#         print(\"x3 shape:\", x3.shape)\n",
    "        x4 = self.down3(x3)\n",
    "#         print(\"x4 shape:\", x4.shape)\n",
    "        x5 = self.down4(x4)\n",
    "#         print(\"x5 shape:\", x5.shape)\n",
    "        x = self.up1(x5, x4)\n",
    "#         print(\"x shape:\", x.shape)\n",
    "        \n",
    "        x = self.up2(x, x3)\n",
    "#         print(\"x shape:\", x.shape)\n",
    "        x = self.up3(x, x2)\n",
    "#         print(\"x shape:\", x.shape)\n",
    "        x = self.up4(x, x1)\n",
    "#         print(\"x shape:\", x.shape)\n",
    "        x = self.out(x)\n",
    "#         print(\"x shape:\", x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf90df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "# 创建一个大小为 [1, 3, 256, 256] 的张量\n",
    "input_tensor = torch.rand(1, 3, 368, 640)\n",
    "\n",
    "# 将张量传递给模型进行前向传播\n",
    "output_tensor = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26c7fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "\n",
    "def train_net(net, train_loader, val_loader, num_epochs=10, learning_rate=0.001, device='cpu', save_mode=''):\n",
    "    # 将模型移动到指定设备\n",
    "    net.to(device)\n",
    "    \n",
    "    # 定义损失函数和优化器\n",
    "    criterion = MS_SSIM(data_range=1, size_average=True, channel=3).cuda() # channel=1 for grayscale images\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    loss_record = []\n",
    "    acc_record = []\n",
    "    \n",
    "    # 训练模型\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train() # 将模型设为训练模式\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            # 将梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 前向传播，计算预测结果和损失\n",
    "            outputs = net(inputs)\n",
    "            loss = 1 - criterion(outputs, labels)\n",
    "            \n",
    "            # 保存loss值最小的网络参数\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                torch.save(net.state_dict(), f'{save_mode}/best_model.pth')\n",
    "            \n",
    "            # 反向传播，更新参数\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 统计损失\n",
    "            train_loss += loss.item()\n",
    "            loss_record.append(loss.item())\n",
    "            \n",
    "            acc = ms_ssim(labels, outputs, data_range=1)\n",
    "            acc_record.append(acc.item())\n",
    "            \n",
    "        torch.save(net.state_dict(), f'{save_mode}/epoch_{epoch}_model.pth')\n",
    "        \n",
    "        # 在验证集上测试模型，并记录损失\n",
    "        net.eval() # 将模型设为测试模式\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_loader):\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                \n",
    "                # 前向传播，计算预测结果和损失\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # 统计损失\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        save_image(outputs, f'dataset_gopro/test/epoch_{epoch}.png')\n",
    "        # 打印每个epoch的损失\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}\")\n",
    "        \n",
    "    return acc_record, loss_record\n",
    "\n",
    "def save_metrics_to_json(metrics, filepath):\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181561c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a802421",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhenRong\\.conda\\envs\\yolov5\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.10607190515632343, Val Loss: 0.8433551812171936\n",
      "Epoch 2/100, Train Loss: 0.0864009564356911, Val Loss: 0.8483907395601272\n",
      "Epoch 3/100, Train Loss: 0.08402821057455201, Val Loss: 0.8495020988583565\n",
      "Epoch 4/100, Train Loss: 0.08305414730771224, Val Loss: 0.8482861316204071\n",
      "Epoch 5/100, Train Loss: 0.08110552951879335, Val Loss: 0.8504818809032441\n",
      "Epoch 6/100, Train Loss: 0.08000567369627537, Val Loss: 0.8516104653477669\n",
      "Epoch 7/100, Train Loss: 0.07910770385937203, Val Loss: 0.8513755306601525\n",
      "Epoch 8/100, Train Loss: 0.07779405806724568, Val Loss: 0.8539001449942589\n",
      "Epoch 9/100, Train Loss: 0.0770530879051608, Val Loss: 0.8549953383207322\n",
      "Epoch 10/100, Train Loss: 0.07714683768755183, Val Loss: 0.8544245940446854\n",
      "Epoch 11/100, Train Loss: 0.07506853104232256, Val Loss: 0.8512030106782913\n",
      "Epoch 12/100, Train Loss: 0.07420470782943497, Val Loss: 0.8560220447182655\n",
      "Epoch 13/100, Train Loss: 0.07326092312758106, Val Loss: 0.8560174956917763\n",
      "Epoch 14/100, Train Loss: 0.07230721477261208, Val Loss: 0.8545284572243691\n",
      "Epoch 15/100, Train Loss: 0.07158567290056377, Val Loss: 0.8541577017307281\n",
      "Epoch 16/100, Train Loss: 0.0708421129835514, Val Loss: 0.8511816447973252\n",
      "Epoch 17/100, Train Loss: 0.07028333727558354, Val Loss: 0.8563809189200401\n",
      "Epoch 18/100, Train Loss: 0.06927704008440128, Val Loss: 0.8554474073648453\n",
      "Epoch 19/100, Train Loss: 0.06822269441480945, Val Loss: 0.8599960228800774\n",
      "Epoch 20/100, Train Loss: 0.06774733310328457, Val Loss: 0.860767970085144\n",
      "Epoch 21/100, Train Loss: 0.06706200187045737, Val Loss: 0.8582966822385788\n",
      "Epoch 22/100, Train Loss: 0.06616411348828057, Val Loss: 0.8567858132719993\n",
      "Epoch 23/100, Train Loss: 0.06631217365550282, Val Loss: 0.8595262759923935\n",
      "Epoch 24/100, Train Loss: 0.06503678126228123, Val Loss: 0.8596124395728111\n",
      "Epoch 25/100, Train Loss: 0.06402019550675465, Val Loss: 0.8587465885281563\n",
      "Epoch 26/100, Train Loss: 0.06302206742198688, Val Loss: 0.8652717345952987\n",
      "Epoch 27/100, Train Loss: 0.06251295546343796, Val Loss: 0.8615037858486175\n",
      "Epoch 28/100, Train Loss: 0.06144660711288452, Val Loss: 0.8649034062027932\n",
      "Epoch 29/100, Train Loss: 0.061827602380529006, Val Loss: 0.8641630703210831\n",
      "Epoch 30/100, Train Loss: 0.06007792557266882, Val Loss: 0.8663683253526687\n",
      "Epoch 31/100, Train Loss: 0.05905537132610407, Val Loss: 0.86579570800066\n",
      "Epoch 32/100, Train Loss: 0.058709698870889566, Val Loss: 0.8638153287768364\n",
      "Epoch 33/100, Train Loss: 0.05838343597707011, Val Loss: 0.8624556219577789\n",
      "Epoch 34/100, Train Loss: 0.060704660237281396, Val Loss: 0.8643325334787368\n",
      "Epoch 35/100, Train Loss: 0.05778977579606739, Val Loss: 0.865240778028965\n",
      "Epoch 36/100, Train Loss: 0.057566482230017604, Val Loss: 0.870304534137249\n",
      "Epoch 37/100, Train Loss: 0.055714206356657414, Val Loss: 0.8688899490237236\n",
      "Epoch 38/100, Train Loss: 0.055182592678545715, Val Loss: 0.8678429028391839\n",
      "Epoch 39/100, Train Loss: 0.054965415946266, Val Loss: 0.8719953206181527\n",
      "Epoch 40/100, Train Loss: 0.05412127163047505, Val Loss: 0.8718408480286598\n",
      "Epoch 41/100, Train Loss: 0.053513934784696585, Val Loss: 0.8664158272743225\n",
      "Epoch 42/100, Train Loss: 0.052810225849437, Val Loss: 0.8716475704312324\n",
      "Epoch 43/100, Train Loss: 0.052238489029710726, Val Loss: 0.874461487531662\n",
      "Epoch 44/100, Train Loss: 0.05164046239971817, Val Loss: 0.8706957513093948\n",
      "Epoch 45/100, Train Loss: 0.050971222042740134, Val Loss: 0.8666238674521446\n",
      "Epoch 46/100, Train Loss: 0.050082236899996635, Val Loss: 0.8718375986814499\n",
      "Epoch 47/100, Train Loss: 0.05193200090579558, Val Loss: 0.8740190929174423\n",
      "Epoch 48/100, Train Loss: 0.04937270915419086, Val Loss: 0.875143767297268\n",
      "Epoch 49/100, Train Loss: 0.04915957424111497, Val Loss: 0.8755065488815308\n",
      "Epoch 50/100, Train Loss: 0.04881928627033186, Val Loss: 0.8762312391400338\n",
      "Epoch 51/100, Train Loss: 0.04764898087912962, Val Loss: 0.8735138657689094\n",
      "Epoch 52/100, Train Loss: 0.04738081333940463, Val Loss: 0.8754513594508171\n",
      "Epoch 53/100, Train Loss: 0.047179086101322695, Val Loss: 0.8769146201014518\n",
      "Epoch 54/100, Train Loss: 0.04617785084574597, Val Loss: 0.8780446952581406\n",
      "Epoch 55/100, Train Loss: 0.0457648890571404, Val Loss: 0.877077354490757\n",
      "Epoch 56/100, Train Loss: 0.04516407319732438, Val Loss: 0.873381516635418\n",
      "Epoch 57/100, Train Loss: 0.04493175004783117, Val Loss: 0.8773969122767449\n",
      "Epoch 58/100, Train Loss: 0.044571750181868784, Val Loss: 0.8777658525109291\n",
      "Epoch 59/100, Train Loss: 0.043462411869791086, Val Loss: 0.8756074786186219\n",
      "Epoch 60/100, Train Loss: 0.04333618944719843, Val Loss: 0.8740620136260986\n",
      "Epoch 61/100, Train Loss: 0.04285915861105978, Val Loss: 0.8737869685888291\n",
      "Epoch 62/100, Train Loss: 0.04216562735469561, Val Loss: 0.8714250177145004\n",
      "Epoch 63/100, Train Loss: 0.04148412360217506, Val Loss: 0.8798523935675621\n",
      "Epoch 64/100, Train Loss: 0.041400176925849436, Val Loss: 0.8779570430517196\n",
      "Epoch 65/100, Train Loss: 0.04093127729292225, Val Loss: 0.8721720194816589\n",
      "Epoch 66/100, Train Loss: 0.04040785561178688, Val Loss: 0.8781987544894219\n",
      "Epoch 67/100, Train Loss: 0.03999250190810967, Val Loss: 0.8776285165548324\n",
      "Epoch 68/100, Train Loss: 0.04025147219845779, Val Loss: 0.8804936391115189\n",
      "Epoch 69/100, Train Loss: 0.03870573231109657, Val Loss: 0.8772779196500778\n",
      "Epoch 70/100, Train Loss: 0.03862172781380632, Val Loss: 0.880984119772911\n",
      "Epoch 71/100, Train Loss: 0.03830103802859337, Val Loss: 0.8777371582388878\n",
      "Epoch 72/100, Train Loss: 0.03864023067112873, Val Loss: 0.8769146355986596\n",
      "Epoch 73/100, Train Loss: 0.03814622291602993, Val Loss: 0.8746045941114425\n",
      "Epoch 74/100, Train Loss: 0.0374422812105117, Val Loss: 0.8782668578624725\n",
      "Epoch 75/100, Train Loss: 0.036454502037933045, Val Loss: 0.8778756618499756\n",
      "Epoch 76/100, Train Loss: 0.03623630117597128, Val Loss: 0.8760633367300034\n",
      "Epoch 77/100, Train Loss: 0.03650191909357199, Val Loss: 0.8778105878829956\n",
      "Epoch 78/100, Train Loss: 0.035490925026653415, Val Loss: 0.8771479314565659\n",
      "Epoch 79/100, Train Loss: 0.03545223670707379, Val Loss: 0.8777164003252983\n",
      "Epoch 80/100, Train Loss: 0.035627357828944106, Val Loss: 0.8800419047474861\n",
      "Epoch 81/100, Train Loss: 0.034263841083222196, Val Loss: 0.8804330310225487\n",
      "Epoch 82/100, Train Loss: 0.03474770698166845, Val Loss: 0.879837856888771\n",
      "Epoch 83/100, Train Loss: 0.03449246874473933, Val Loss: 0.8805759754776955\n",
      "Epoch 84/100, Train Loss: 0.033562282523014894, Val Loss: 0.8802038031816483\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size = 4\n",
    "net = UNet()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print (\"multi GPUs\")\n",
    "    net = nn.DataParallel(net,device_ids = [0, 1])\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(size=((256,256))),\n",
    "#     transforms.RandomVerticalFlip(p = 0.5),\n",
    "    transforms.Resize((368, 640)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "# 指定训练集地址，开始训练\n",
    "train_data_path = \"dataset_gopro/train\"\n",
    "gopro_dataset = Gopro_Loader(data_path=train_data_path, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                                        dataset=gopro_dataset,\n",
    "                                        batch_size=batch_size, \n",
    "                                        shuffle=True)\n",
    "\n",
    "test_data_path = \"dataset_gopro/eval\"\n",
    "gopro_test_dataset = Gopro_Loader(data_path=test_data_path, transform=transform_test)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "                                        dataset=gopro_test_dataset,\n",
    "                                        batch_size=1, \n",
    "                                        shuffle=True)\n",
    "\n",
    "acc_record, loss_record = train_net(net, train_loader, val_loader, num_epochs=100, learning_rate=0.001, device=device, save_model='CNN_HW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0e552b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = {\"accuracy\": acc_record, \"loss\": loss_record}\n",
    "save_metrics_to_json(metrics, 'CNN_HW/metrics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e4fbd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afe2a04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(net, device, epoch_num, test_loader):\n",
    "    \n",
    "    net.load_state_dict(torch.load(f'CNN_HW/{epoch_num}model.pth', map_location=device))\n",
    "    # 测试模式\n",
    "    net.eval()\n",
    "\n",
    "    criterion = MS_SSIM(data_range=1, size_average=True, channel=3).cuda() # reuse the gaussian kernel with SSIM & MS_SSIM.\n",
    "\n",
    "    count = 0\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device=device), y.to(device=device)\n",
    "        with torch.no_grad():\n",
    "            pred = net(x)\n",
    "            save_image(pred, f'dataset_gopro/test/{epoch_num}{count}.png')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c446886d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi GPUs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m Gopro_Loader(data_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_gopro/test\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m     19\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset\u001b[38;5;241m=\u001b[39mtest_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 19\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(net, device, epoch_num, test_loader)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     18\u001b[0m     pred \u001b[38;5;241m=\u001b[39m net(x)\n\u001b[1;32m---> 19\u001b[0m     \u001b[43msave_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset_gopro/test/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch_num\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcount\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolov5\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolov5\\lib\\site-packages\\torchvision\\utils.py:158\u001b[0m, in \u001b[0;36msave_image\u001b[1;34m(tensor, fp, format, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m grid \u001b[38;5;241m=\u001b[39m make_grid(tensor, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# Add 0.5 after unnormalizing to [0, 255] to round to nearest integer\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m ndarr \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclamp_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    159\u001b[0m im \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(ndarr)\n\u001b[0;32m    160\u001b[0m im\u001b[38;5;241m.\u001b[39msave(fp, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 选择设备，有cuda用cuda，没有就用cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = UNet()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print (\"multi GPUs\")\n",
    "    net = nn.DataParallel(net,device_ids = [0, 1])\n",
    "net.to(device=device)\n",
    "\n",
    "# 加载模型参数\n",
    "epoch_num = 'epoch_0_'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "#     transforms.Resize((368, 640)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_dataset = Gopro_Loader(data_path='dataset_gopro/test', transform=transform)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "test_model(net, device, epoch_num, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f379770b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi GPUs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m criterion \u001b[38;5;241m=\u001b[39m MS_SSIM(data_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, size_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, channel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda() \u001b[38;5;66;03m# reuse the gaussian kernel with SSIM & MS_SSIM.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m     38\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice), y\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolov5\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolov5\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolov5\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolov5\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[1], line 31\u001b[0m, in \u001b[0;36mGopro_Loader.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     28\u001b[0m label \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(label_path)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 31\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(label)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img, label\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolov5\\lib\\site-packages\\torchvision\\transforms\\transforms.py:94\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 94\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolov5\\lib\\site-packages\\torchvision\\transforms\\transforms.py:134\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolov5\\lib\\site-packages\\torchvision\\transforms\\functional.py:164\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[0;32m    163\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[1;32m--> 164\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    167\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 选择设备，有cuda用cuda，没有就用cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 加载网络，图片三通道，分类为1。\n",
    "net = UNet()\n",
    "# 将网络拷贝到device中\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print (\"multi GPUs\")\n",
    "    net = nn.DataParallel(net,device_ids = [0, 1])\n",
    "net.to(device=device)\n",
    "\n",
    "# 加载模型参数\n",
    "net.load_state_dict(torch.load('CNN_HW/epoch_0_model.pth', map_location=device))\n",
    "# 测试模式\n",
    "net.eval()\n",
    "\n",
    "loss_record = []\n",
    "acc_record = []\n",
    "tmp_pred = torch.zeros(1)\n",
    "tmp_y = torch.zeros(1)\n",
    "tmp_x = torch.zeros(1)\n",
    "tmp_acc = 0\n",
    "\n",
    "transform = transforms.Compose([\n",
    "#     transforms.Resize((368, 640)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_dataset = Gopro_Loader(data_path='dataset_gopro/test', transform=transform)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "criterion = MS_SSIM(data_range=1, size_average=True, channel=3).cuda() # reuse the gaussian kernel with SSIM & MS_SSIM.\n",
    "\n",
    "count = 0\n",
    "for x, y in test_loader:\n",
    "    x, y = x.to(device=device), y.to(device=device)\n",
    "    with torch.no_grad():\n",
    "        pred = net(x)\n",
    "        save_image(pred, f'dataset_gopro/test/{count}.png')\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d1679e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0054, -0.1675, -0.1609,  ..., -0.1774, -0.0273,  0.0629],\n",
       "          [-0.2080, -0.4057, -0.4016,  ..., -0.3591, -0.1425,  0.0419],\n",
       "          [-0.1860, -0.3849, -0.3467,  ..., -0.2360, -0.0016,  0.1465],\n",
       "          ...,\n",
       "          [ 0.2849,  0.3475,  0.4042,  ...,  0.6581,  0.5788,  0.4309],\n",
       "          [ 0.2858,  0.3381,  0.3899,  ...,  0.5763,  0.4839,  0.3844],\n",
       "          [ 0.2304,  0.2728,  0.3027,  ...,  0.3843,  0.3445,  0.3091]],\n",
       "\n",
       "         [[ 0.4628,  0.5244,  0.5164,  ...,  0.5609,  0.4948,  0.4322],\n",
       "          [ 0.5276,  0.6672,  0.6536,  ...,  0.7334,  0.5765,  0.4565],\n",
       "          [ 0.5093,  0.6151,  0.5571,  ...,  0.6167,  0.4612,  0.4102],\n",
       "          ...,\n",
       "          [ 0.3115,  0.2754,  0.2659,  ...,  0.1753,  0.1963,  0.2625],\n",
       "          [ 0.3308,  0.2858,  0.2752,  ...,  0.1958,  0.2114,  0.2851],\n",
       "          [ 0.3538,  0.3198,  0.2944,  ...,  0.2435,  0.2623,  0.3201]],\n",
       "\n",
       "         [[ 0.4125,  0.4656,  0.4395,  ...,  0.4606,  0.4262,  0.4089],\n",
       "          [ 0.4661,  0.5883,  0.5606,  ...,  0.5731,  0.4395,  0.3916],\n",
       "          [ 0.4522,  0.5471,  0.4676,  ...,  0.4336,  0.3075,  0.3228],\n",
       "          ...,\n",
       "          [ 0.3571,  0.3188,  0.2890,  ...,  0.1476,  0.1722,  0.2502],\n",
       "          [ 0.3669,  0.3252,  0.2993,  ...,  0.1672,  0.1889,  0.2668],\n",
       "          [ 0.3845,  0.3449,  0.3196,  ...,  0.2297,  0.2536,  0.3190]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b52aaf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset_gopro/test/blur\\\\GOPR0871_11_01_000181.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000182.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000183.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000184.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000185.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000186.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000187.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000188.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000189.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000190.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000191.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000192.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000193.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000194.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000195.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000196.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000197.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000198.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000199.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000200.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000201.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000202.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000203.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000204.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000205.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000206.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000207.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000208.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000209.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000210.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000211.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000212.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000213.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000214.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000215.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000216.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000217.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000218.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000219.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000220.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000221.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000222.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000223.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000224.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000225.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000226.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000227.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000228.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000229.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000230.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000231.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000232.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000233.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000234.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000235.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000236.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000237.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000238.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000239.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000240.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000241.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000242.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000243.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000244.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000245.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000246.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000247.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000248.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000249.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000250.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000251.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000252.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000253.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000254.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000255.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000256.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000257.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000258.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000259.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000260.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000261.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000262.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000263.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000264.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000265.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000266.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000267.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000268.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000269.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000270.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000271.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000272.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000273.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000274.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000275.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000276.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000277.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000278.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000279.png', 'dataset_gopro/test/blur\\\\GOPR0871_11_01_000280.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000001.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000002.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000003.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000004.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000005.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000006.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000007.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000008.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000009.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000010.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000011.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000012.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000013.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000014.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000015.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000016.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000017.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000018.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000019.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000020.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000021.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000022.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000023.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000024.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000025.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000026.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000027.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000028.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000029.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000030.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000031.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000032.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000033.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000034.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000035.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000036.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000037.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000038.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000039.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000040.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000041.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000042.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000043.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000044.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000045.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000046.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000047.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000048.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000049.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000050.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000051.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000052.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000053.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000054.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000055.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000056.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000057.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000058.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000059.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000060.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000061.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000062.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000063.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000064.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000065.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000066.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000067.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000068.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000069.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000070.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000071.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000072.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000073.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000074.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000075.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000076.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000077.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000078.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000079.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000080.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000081.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000082.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000083.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000084.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000085.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000086.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000087.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000088.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000089.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000090.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000091.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000092.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000093.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000094.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000095.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000096.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000097.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000098.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000099.png', 'dataset_gopro/test/blur\\\\GOPR0881_11_00_000100.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000186.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000187.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000188.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000189.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000190.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000191.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000192.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000193.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000194.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000195.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000196.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000197.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000198.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000199.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000200.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000201.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000202.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000203.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000204.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000205.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000206.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000207.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000208.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000209.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000210.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000211.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000212.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000213.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000214.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000215.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000216.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000217.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000218.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000219.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000220.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000221.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000222.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000223.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000224.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000225.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000226.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000227.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000228.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000229.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000230.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000231.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000232.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000233.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000234.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000235.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000236.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000237.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000238.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000239.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000240.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000241.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000242.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000243.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000244.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000245.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000246.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000247.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000248.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000249.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000250.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000251.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000252.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000253.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000254.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000255.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000256.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000257.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000258.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000259.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000260.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000261.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000262.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000263.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000264.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000265.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000266.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000267.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000268.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000269.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000270.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000271.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000272.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000273.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000274.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000275.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000276.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000277.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000278.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000279.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000280.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000281.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000282.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000283.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000284.png', 'dataset_gopro/test/blur\\\\GOPR0884_11_00_000285.png']\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n",
      "(720, 1280, 3)\n",
      "(1, 3, 256, 256)\n",
      "x shape: torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "(1, 3, 256, 256)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m save_res_path \u001b[38;5;241m=\u001b[39m test_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_res.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 读取图片\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m (img\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 转为batch为1，通道为1，大小为512*512的数组\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 选择设备，有cuda用cuda，没有就用cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 加载网络，图片三通道，分类为1。\n",
    "net = UNet()\n",
    "# 将网络拷贝到device中\n",
    "net.to(device=device)\n",
    "# 加载模型参数\n",
    "net.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "# 测试模式\n",
    "net.eval()\n",
    "\n",
    "tests_path = glob.glob('dataset_gopro/test/blur/*.png')\n",
    "print (tests_path)\n",
    "\n",
    "# 遍历所有图片\n",
    "for test_path in tests_path:\n",
    "    # 保存结果地址\n",
    "    save_res_path = test_path.split('.')[0] + '_res.png'\n",
    "    # 读取图片\n",
    "    img = cv2.imread(test_path)\n",
    "    print (img.shape)\n",
    "    # 转为batch为1，通道为1，大小为512*512的数组\n",
    "    img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "    img = img.reshape(1, 3, img.shape[0], img.shape[1])\n",
    "    print (img.shape)\n",
    "    # 转为tensor\n",
    "    img_tensor = torch.from_numpy(img)\n",
    "    \n",
    "    # 将数据拷贝到device中\n",
    "    image = img_tensor.to(device=device, dtype=torch.float32)\n",
    "    # 使用网络参数，输出预测结果\n",
    "    pred = net(image)\n",
    "    print (pred.shape)\n",
    "    \n",
    "    pred = pred.detach().cpu().numpy()\n",
    "\n",
    "    print (pred.shape)\n",
    "    # 保存图片\n",
    "    save_res_path = test_path.split('.')[0] + '_res.png'\n",
    "    cv2.imwrite(save_res_path, pred[0].transpose(1, 2, 0).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5932a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1120",
   "language": "python",
   "name": "yolov5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
